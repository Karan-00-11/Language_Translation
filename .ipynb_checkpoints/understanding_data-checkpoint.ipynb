{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0716138-1480-4dc7-af66-9889fe26fdd3",
   "metadata": {},
   "source": [
    "### Source-\n",
    "https://github.com/Alejandro-Garcia-Uceda/Translators-with-RNNs/blob/main/Basic%20bidirectional%20LSTM%20translator%20from%20English%20to%20French.ipynb\n",
    "https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4a7b59-4050-4ead-8560-d741780faf1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import indicnlp\n",
    "import indicnlp.tokenize\n",
    "from indicnlp.tokenize.indic_tokenize import trivial_tokenize_indic\n",
    "# from indicnlp.tokenize.\n",
    "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "import unicodedata\n",
    "import re\n",
    "from io import open\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba129ab4-ca42-4754-8fc9-2d58e9855bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39b49c2-6a32-4cc3-a0ae-3839ab4c9401",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c0108cf-70df-4ff6-bfde-828f2deb7f2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84473cc2-76c1-4694-9a21-b6417fe3dd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55ec3c8f-c3e8-4b5d-ba7f-b6d31160ef63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc4c75-19cf-4886-acef-72eda5530ab6",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "556e069d-14c7-4832-808c-047b83ecb00a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self,lang):\n",
    "        self.lang=lang\n",
    "        self.word2index={}\n",
    "        self.word2count={}\n",
    "        self.index2word={1:\"SOS\",2:\"EOS\"}\n",
    "        self.n_words=2\n",
    "    \n",
    "    def unicodeToAscii(self,s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "\n",
    "    def normalizeString(self,s):\n",
    "        s = self.unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?,])\", r\" \\1 \", s)\n",
    "        s = re.sub(r\"[^a-zA-Z!?]+\", \" \", s)\n",
    "        return s.strip()\n",
    "\n",
    "    \n",
    "    def normal(self,text):\n",
    "        if self.lang==\"ta\":\n",
    "            text=re.sub(r'([.!?,])', r' \\1 ', text)\n",
    "            # text = re.sub(r'[]',r'\\1', text)\n",
    "            norm=IndicNormalizerFactory()\n",
    "            n=norm.get_normalizer('ta')\n",
    "            string=n.normalize(text)\n",
    "            string.strip()\n",
    "        else:\n",
    "            string=self.normalizeString(text)\n",
    "            \n",
    "        return string.strip()\n",
    "    \n",
    "    def token(self,text):\n",
    "        if self.lang==\"ta\":\n",
    "            # print(self.lang)\n",
    "            text=self.normal(text)\n",
    "            words=trivial_tokenize_indic(text)\n",
    "\n",
    "        else:\n",
    "            # print(self.lang)\n",
    "            text=self.normal(text)\n",
    "            words=[word for word in text.split(' ')]\n",
    "\n",
    "        for word in words:\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word]=self.n_words\n",
    "                self.word2count[word]=1\n",
    "                self.index2word[self.n_words]=word\n",
    "                self.n_words+=1\n",
    "\n",
    "            else:\n",
    "                self.word2count[word]+=1\n",
    "                    \n",
    "\n",
    " \n",
    "                   \n",
    "                \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2169f81e-b648-42ed-ac17-b9cf97d57854",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def readData():\n",
    "    data=pd.read_csv(\"D:\\\\Language Translation\\\\first_attempt.ipynb\\\\data\\\\ta-en.txt\",delimiter=\"\\t\",header=None,on_bad_lines='skip')\n",
    "    tamil_text=[ i for i in data.iloc[:,0] ]\n",
    "    eng_text=[ i for i in data.iloc[:,1] ]\n",
    "    count=0\n",
    "\n",
    "    \n",
    "    tamil_vocabs=Lang('ta')\n",
    "    eng_vocabs=Lang('eng')\n",
    "    for i in tamil_text:\n",
    "        tamil_vocabs.token(i)\n",
    "    \n",
    "    for i in eng_text:\n",
    "        eng_vocabs.token(i)\n",
    "    return tamil_vocabs,eng_vocabs,tamil_text,eng_text\n",
    "    \n",
    "tamil,eng,tamil_text,eng_text=readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd243194-8869-46fb-93b3-1e1d81a91c3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng.word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ccdb07-26e2-4cdd-a52d-176aa5003847",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preparaing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26ed26a1-ee27-4d23-9d07-71376fd4bb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    sentence=lang.normal(sentence)\n",
    "    return [lang.word2index[word] for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5090c5e-6cdc-444f-a0c2-b5345111c8bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test=\"நீ எங்கே இருக்கிறாய்?\"\n",
    "test1=\"Where are you?\"\n",
    "test_res=indexesFromSentence(tamil,test)\n",
    "test1_res=indexesFromSentence(eng,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a3f638-6350-4290-879d-73f0c2ba92fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 19, 22, 17] \n",
      " [17, 18, 4, 16]\n"
     ]
    }
   ],
   "source": [
    "print(test_res,\"\\n\",test1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0597541-117c-43cc-a385-50f852fe02a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6f92d66-99af-4327-9bc5-3f3d036e7801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test2_res=tensorFromSentence(tamil,test)\n",
    "test3_res=tensorFromSentence(eng,test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf588d08-2b03-4a1d-b57b-424464703b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21, 19, 22, 17, 2] \n",
      " [17, 18, 4, 16, 2]\n"
     ]
    }
   ],
   "source": [
    "print(test2_res,\"\\n\",test3_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f224741-335b-4380-ba7d-63004b165e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensorsFromPair(sen1,sen2):\n",
    "    input_tensor = tensorFromSentence(tamil, sen1)\n",
    "    target_tensor = tensorFromSentence(eng, sen2)\n",
    "    return input_tensor, target_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7522ad8b-0a13-4bd5-b9f2-c045c0192b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_tensors(tensors,num):\n",
    "    \"\"\"\n",
    "    Takes a list of `N` M-dimensional tensors (M<4) and returns a padded tensor.\n",
    "\n",
    "    The padded tensor is `M+1` dimensional with size `N, S1, S2, ..., SM`\n",
    "    where `Si` is the maximum value of dimension `i` amongst all tensors.\n",
    "    \"\"\"\n",
    "    rep = tensors[0]\n",
    "    padded_dim = []\n",
    "    for dim in range(rep.dim()):\n",
    "        max_dim = max([tensor.size(dim) for tensor in tensors])\n",
    "        padded_dim.append(num)\n",
    "    padded_dim = [len(tensors)] + padded_dim\n",
    "    padded_tensor = torch.zeros(padded_dim)\n",
    "    padded_tensor = padded_tensor.type_as(rep)\n",
    "    for i, tensor in enumerate(tensors):\n",
    "        size = list(tensor.size())\n",
    "        if len(size) == 1:\n",
    "            padded_tensor[i, :size[0]] = tensor\n",
    "        elif len(size) == 2:\n",
    "            padded_tensor[i, :size[0], :size[1]] = tensor\n",
    "        elif len(size) == 3:\n",
    "            padded_tensor[i, :size[0], :size[1], :size[2]] = tensor\n",
    "        else:\n",
    "             raise ValueError('Padding is supported for upto 3D tensors at max.')\n",
    "    return padded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c693a2ae-23c3-4609-a3c9-851dccfdaa95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ints_to_tensor(ints,num=28):\n",
    "    \"\"\"\n",
    "    Converts a nested list of integers to a padded tensor.\n",
    "    \"\"\"\n",
    "    if isinstance(ints, torch.Tensor):\n",
    "        return ints\n",
    "    if isinstance(ints, list):\n",
    "        if isinstance(ints[0], int):\n",
    "            return torch.LongTensor(ints)\n",
    "        if isinstance(ints[0], torch.Tensor):\n",
    "            return pad_tensors(ints,num)\n",
    "        if isinstance(ints[0], list):\n",
    "            return ints_to_tensor([ints_to_tensor(inti) for inti in ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed0600af-1f08-47c3-a420-eddc91502272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dataPreparation():\n",
    "    train=[]\n",
    "    input_tensors=[]\n",
    "    label_tensors=[]\n",
    "    for i, (x, y) in enumerate(zip(tamil_text, eng_text)):\n",
    "        i,o=tensorsFromPair(x,y)\n",
    "        input_tensors.append(i)\n",
    "        label_tensors.append(o)\n",
    "    \n",
    "    input_tensor=ints_to_tensor(input_tensors,num=28)\n",
    "    output_tensor=ints_to_tensor(label_tensors,num=28)\n",
    "    train_data=TensorDataset(input_tensor.to(device),output_tensor.to(device))\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler)\n",
    "    \n",
    "    return train_data,train_dataloader,input_tensor,output_tensor\n",
    "    \n",
    "    \n",
    "train_data,train_dataloader,x,y=dataPreparation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dcf2f9-2d5b-4667-843b-f5bbe63778f2",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07693c63-737e-45a9-95cb-4ca978d20258",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d61c65ad-fdf8-45ee-85c3-d3dede2ee199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (emb): Embedding(1091, 250, padding_idx=0)\n",
      "  (LSTM1): LSTM(250, 250, batch_first=True, dropout=0.5)\n",
      "  (Dense1): Linear(in_features=250, out_features=3670, bias=True)\n",
      "  (Dense2): Linear(in_features=3670, out_features=734, bias=True)\n",
      "  (batch_norm1): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batch_norm2): BatchNorm1d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    def __init__(self, en_dic =tamil.n_words, fr_dic=eng.n_words, device='cpu'):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.emb = nn.Embedding(en_dic, 250,padding_idx=0)            \n",
    "        \n",
    "        self.LSTM1 = nn.LSTM(250, 250, num_layers=1, batch_first=True, dropout=0.5)\n",
    "        \n",
    "        self.Dense1 = nn.Linear(250, fr_dic*5)\n",
    "        self.Dense2 = nn.Linear(fr_dic*5, fr_dic)\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(23)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(23)\n",
    "        \n",
    "        self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        self.batch_size = x.shape[0]\n",
    "        self.hidden = ( torch.zeros(1, self.batch_size, 250).to(self.device), \n",
    "                       torch.zeros(1, self.batch_size, 250).to(self.device) )\n",
    "        \n",
    "        x = self.emb(x)\n",
    "        out, self.hidden = self.LSTM1(x, self.hidden)\n",
    "        out = F.relu(out) \n",
    "        out = self.Dense1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.Dense2(out)\n",
    "        \n",
    "        return(out)\n",
    "    \n",
    "print(RNN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "131d471d-2df7-41c0-84d9-bf700ca3174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 10\n",
    "# device = 'cuda'\n",
    "device = 'cpu'\n",
    "display_step = 100\n",
    "rnn = RNN().to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "\n",
    "tr_ds = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "acef1c54-1e0b-4426-a42c-619c241a5f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44ac4e22e1641fbad0ddcc8d03bc2e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e360cebe3c4840ba571549c68d120f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38360d9035754780bfab716281fa20cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91581a3a6f734c8daa84fdf912b02434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6537688ca72d46d5bb6b199ffe627f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130378771707460e94636dd0b5a5c67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165054703f3845d4a03faaa17f1148e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69d98d8a8f14a1f82f1cab5ce41eb39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79534c68fa914e29afdf9e6723383748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3e9b881bb14388a31692499d89fdc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h_loss = []\n",
    "h_loss_it = []\n",
    "val_loss = []\n",
    "val_loss_it = []\n",
    "avg_loss = 0\n",
    "count = 0\n",
    "T_it = 0\n",
    "best_model = False\n",
    "\n",
    "it = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for ta, en in tqdm(tr_ds):\n",
    "        it += 1\n",
    "        T_it += 1\n",
    "        \n",
    "        ta = ta.to(device)\n",
    "        en = en.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = rnn(ta)\n",
    "        loss = criterion(pred.view(-1,eng.n_words), en.view(-1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += pred.shape[0]\n",
    "        avg_loss += loss.item() * pred.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4ed6d616-dcca-4ae9-9f6a-660c4ebbdb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(),\"Models/LSTM.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff701001-6ca5-44c1-9eb5-0c46d654a9b0",
   "metadata": {},
   "source": [
    "### GRU ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43d12d82-bbc5-4319-ae7b-a1cc76ac168e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(\n",
      "  (emb): Embedding(1091, 64)\n",
      "  (GRU1): GRU(64, 64, batch_first=True)\n",
      "  (dense1): Linear(in_features=64, out_features=2202, bias=True)\n",
      "  (dense2): Linear(in_features=2202, out_features=734, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self,t_dic=tamil.n_words,e_dic=eng.n_words,device='cpu'):\n",
    "        super(GRU,self).__init__()\n",
    "        self.device=device\n",
    "        self.emb=nn.Embedding(t_dic,64)\n",
    "        self.GRU1=nn.GRU(64,64,num_layers=1,batch_first=True)\n",
    "        self.dense1=nn.Linear(64,3*e_dic)\n",
    "        self.dense2 = nn.Linear(e_dic*3, e_dic)\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.batch_size=x.shape[0]\n",
    "        self.hidden = ( torch.zeros(1, self.batch_size, 64).to(self.device) )\n",
    "        x=self.emb(x)\n",
    "        out,self.hidden=self.GRU1(x,self.hidden)\n",
    "        out=F.relu(out)\n",
    "        out=self.dense1(out)\n",
    "        out=F.relu(out)\n",
    "        out=self.dense2(out)\n",
    "        return (out)\n",
    "\n",
    "print(GRU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b8477e2f-83cd-4a81-800c-ad6260dc15d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 10\n",
    "device = 'cpu'\n",
    "display_step = 100\n",
    "gru = GRU().to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
    "tr_ds = DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e19f8fb3-3515-4eee-bd95-0d2cd8980eca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea9b085e17548a4b3bf1ec81b1cd84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba503d0b23ca44e3973e627342180ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce483601adb54da5b00daab431d1ba98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b7f6247bf04994972108cdc903a8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b69cfc46b44e578fd28ea98cc2194b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b42031f8d5e4faca32b0ebf8d9b851f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a8adfe6a924a119e87ccc306f494ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef2ece597c43c69db3df6f20fe09f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042a745c3a6c4e3699ed38a192209b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "371a4ea0b85d47269fa97f48dc9f954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "count = 0\n",
    "T_it = 0\n",
    "it = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for ta, en in tqdm(tr_ds):\n",
    "        it += 1\n",
    "        T_it += 1\n",
    "        \n",
    "        ta = ta.to(device)\n",
    "        en = en.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = gru(ta)\n",
    "        loss = criterion(pred.view(-1,eng.n_words), en.view(-1)) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += pred.shape[0]\n",
    "        avg_loss += loss.item() * pred.shape[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "16884759-73cb-4cbf-97c1-a76ab15dda1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(rnn.state_dict(),\"Models/GRU.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab8708-8dcc-4063-95f9-e41cae1dea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langtrans",
   "language": "python",
   "name": "langtrans"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
